{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"api key : \")\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "index_name = \"langchain-test-index\" \n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "# if index_name not in existing_indexes:\n",
    "#     pc.create_index(\n",
    "#         name=index_name,\n",
    "#         dimension=384,\n",
    "#         metric=\"cosine\",\n",
    "#         spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "#     )\n",
    "#     while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "#         time.sleep(1)\n",
    "\n",
    "# index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp\\ipykernel_21972\\4238859041.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "extracted_data = load_pdf(\"./data/\")\n",
    "text_chunks = text_split(extracted_data)\n",
    "embeddings = download_hugging_face_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "docsearch=Pinecone.from_texts(\n",
    "    [t.page_content for t in text_chunks],\n",
    "    embeddings,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "docsearch = Pinecone.from_existing_index(index_name, embeddings)\n",
    "\n",
    "# query = \"What are Allegries\"\n",
    "# docs = docsearch.similarity_search(query, k = 3)\n",
    "# print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers\n",
    "llm = CTransformers(model=\"../model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                      model_type=\"llama\",\n",
    "                      config={'max_new_tokens':512,\n",
    "                              'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import RetrievalQA\n",
    "\n",
    "# qa = RetrievalQA.from_chain_type(\n",
    "#         llm=llm,\n",
    "#         chain_type=\"stuff\", \n",
    "#         retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "#         return_source_documents=True,\n",
    "#         chain_type_kwargs=chain_type_kwargs_t\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=prompt_template)\n",
    "\n",
    "# qa = RetrievalQA(\n",
    "#     retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "#     chain_type_kwargs=qa_chain,\n",
    "#     return_source_documents=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp\\ipykernel_21972\\166571942.py:23: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
      "  qa_chain = load_qa_chain(llm, chain_type=\"stuff\", **chain_type_kwargs)\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], \n",
    "    template=\"\"\"\n",
    "    Use the following pieces of information to answer the user's question.\n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer\n",
    "\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "\n",
    "    Only return the helpful answer below and nothing else.\n",
    "    Helpful answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": prompt_template}\n",
    "\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"stuff\", **chain_type_kwargs)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input Prompt: \")\n",
    "    result=qa.invoke({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
